{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resultados_excel_latex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgMLhiIKAXuxWYqJuSQTwF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejandro-cermeno/2021_Market_Timing-Cermeno/blob/main/resultados_excel_latex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lEDZBapWWpd"
      },
      "source": [
        "# **1.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdsG_eN-35wt"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Instalacion\n",
        "\n",
        "!pip install arch\n",
        "\n",
        "\n",
        "# Librerias\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import arch\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Obtencion de datos\n",
        "\n",
        "ruta = 'https://git.io/Jnovh'\n",
        "\n",
        "precios = pd.read_excel(ruta, sheet_name = 'source', index_col = 0)\n",
        "retornos = price2ret(precios)\n",
        "\n",
        "\n",
        "# Etiquetas\n",
        "\n",
        "mercado = ['(MERVAL)', '(IBOV)', '(IPSA)', '(IGBC)', '(MEXBOL)', '(SPBLPGPTR)']\n",
        "pais    = ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Mexico', 'Peru']\n",
        "\n",
        "\n",
        "# Especificaciones\n",
        "\n",
        "  # Media\n",
        "\n",
        "media = ['Zero', 'Constant', 'AR']\n",
        "media_nom = ['Cero', 'Constante', 'AR']\n",
        "\n",
        "  # Varianza\n",
        "\n",
        "arch_params = {'vol': 'ARCH'}\n",
        "garch_params = {'p':1, 'q':1, 'vol':'GARCH'}\n",
        "grj_params = {'p':1, 'o':1, 'q':1, 'vol':'GARCH'}\n",
        "egarch_params = {'p': 1, 'q': 1, 'o': 1, 'vol': 'EGARCH'}\n",
        "\n",
        "varianza = [arch_params, garch_params, grj_params, egarch_params]\n",
        "varianza_nom = ['ARCH', 'GARCH', 'GRJ', 'EGARCH']\n",
        "\n",
        "  # Distribuciones\n",
        "\n",
        "dist = ['normal', 't', 'skewt']\n",
        "dist_nom = ['N', 't', 'sk'] \n",
        "\n",
        "\n",
        "# Almacenamiento de resultados\n",
        "\n",
        "tabla_resultados = pd.DataFrame()"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMBWpDQViOy6"
      },
      "source": [
        "# **2)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUZVXqsUROAZ"
      },
      "source": [
        "def mdl_volatilidad(\n",
        "    ts, media, varianza, dist, media_nom, varianza_nom, dist_nom):\n",
        "\n",
        "   # Especificacion\n",
        "  mdl = arch.arch_model(ts, mean = media, **varianza, dist = dist)\n",
        "  \n",
        "  # Estimacion\n",
        "  mdl = mdl.fit(disp='off')\n",
        "\n",
        "  # Resultados\n",
        "\n",
        "  # Media\n",
        "\n",
        "  media_nom = pd.Series(media_nom, index = ['Media'])\n",
        "\n",
        "  # Varianza\n",
        "\n",
        "  varianza_nom = pd.Series(varianza_nom, index = ['Varianza'])\n",
        "\n",
        "  # Distribucion\n",
        "\n",
        "  dist_nom = pd.Series(dist_nom, index = ['Distribucion'])\n",
        "\n",
        "  # P-values\n",
        "\n",
        "  pvalues = mdl.pvalues\n",
        "\n",
        "  # Coeficientes\n",
        "\n",
        "  coef = round( mdl.params, 3 )\n",
        "\n",
        "  # Log-verosimilutud\n",
        "\n",
        "  loglik = round( mdl.loglikelihood, 3 )\n",
        "  loglik = pd.Series(loglik, index = ['log-lik'])\n",
        "\n",
        "  # Valor del criterio de informacion\n",
        "\n",
        "  bic = round( mdl.bic, 3 )\n",
        "  bic = pd.Series(bic, index = ['BIC'])\n",
        "\n",
        "  # Volatilidad proyectada y observda\n",
        "\n",
        "  vol_proyectada = mdl.conditional_volatility ** 2\n",
        "  vol_observada = ts ** 2\n",
        "\n",
        "  # Ra√≠z del error cuadratico medio (RMSE)\n",
        "\n",
        "  rmse = math.sqrt( mean_squared_error(vol_observada, vol_proyectada) )\n",
        "  mrse = round( rmse, 3 )\n",
        "  rmse = pd.Series(rmse, index = ['RMSE'])\n",
        "\n",
        "  # Tabla resultado\n",
        "\n",
        "  resultado = pd.concat([media_nom, varianza_nom, dist_nom, coef, bic,\n",
        "                             loglik, rmse]) \n",
        "  resultado = pd.DataFrame(resultado).T\n",
        "\n",
        "  return resultado\n",
        "\n",
        "\n",
        "################################################################\n",
        "\n",
        "\n",
        "def price2ret(price):\n",
        "\n",
        "  '''\n",
        "\n",
        "  Convierte los datos contenidos en la serie en price de niveles a retornos.\n",
        "  Requiere numpy.\n",
        "\n",
        "  Entradas:\n",
        "\n",
        "    price: (array_like) Serie de precios. \n",
        "\n",
        "  '''\n",
        "  \n",
        "  ret = (100 * (np.log(price) - np.log(price.shift(1))))\n",
        "  \n",
        "  return ret"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zQsVvbvWii4"
      },
      "source": [
        "## **3.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALRLqgamIW3b"
      },
      "source": [
        "%%capture\n",
        "\n",
        "numero_series = retornos.shape[1]\n",
        "\n",
        "for i in range(0, numero_series):   # Serie\n",
        "\n",
        "  ts = retornos.iloc[:, i].dropna()\n",
        "\n",
        "  for j in range(len(media)):       # Especificacion media\n",
        "\n",
        "    for k in range(len(varianza)):  # Especificacion varianza\n",
        "\n",
        "      for l in range(len(dist)):    # Especificacion distribucion\n",
        "        \n",
        "        # Se fija la cantidad de decimales\n",
        "        pd.set_option('precision', 3)\n",
        "        \n",
        "        resultado = mdl_volatilidad(ts, media[j], varianza[k], dist[l], media_nom[j], varianza_nom[k], dist_nom[l])\n",
        "        tabla_resultados = tabla_resultados.append(resultado, sort=False)\n",
        "\n",
        "  encabezado_pais = {'Media': [pais[i]], 'Varianza': [mercado[i]]}\n",
        "  encabezado_pais = pd.DataFrame.from_dict(encabezado_pais)\n",
        "  tabla_resultados = pd.concat([encabezado_pais, tabla_resultados])"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwO5VmhLlZcT"
      },
      "source": [
        "# **4)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0xI8IC6lX5p"
      },
      "source": [
        "# Modificaciones a la tabla \n",
        "\n",
        "  # Remplazar NaN por espacios en blanco\n",
        "\n",
        "tabla_resultados = tabla_resultados.fillna('')\n",
        "\n",
        "  # Reiniciar el index\n",
        "\n",
        "tabla_resultados = tabla_resultados.reset_index(drop=True)\n",
        "\n",
        "  # Ordenar las columnas\n",
        "  \n",
        "nombres_columnas = list(tabla_resultados.columns)\n",
        "\n",
        "columnas_derecha =  ['BIC',  'log-lik', 'RMSE']\n",
        "columnas_izquierda = [l for l in nombres_columnas if l not in columnas_derecha]\n",
        "\n",
        "orden_columnas = columnas_izquierda + columnas_derecha\n",
        "\n",
        "tabla_resultados = tabla_resultados[orden_columnas]\n",
        "\n",
        "\n",
        "# Exportar resultados\n",
        "\n",
        "  # Excel\n",
        "\n",
        "tabla_resultados.to_excel('resultados_excel.xlsx')  \n",
        "\n",
        "  # LaTeX\n",
        "\n",
        "latex = tabla_resultados.to_latex()\n",
        "\n",
        "#adicionar = '\\resizebox{1\\textwidth}{!}{\\begin{centering}'\n",
        "\n",
        "with open(\"resultados_latex.tex\", \"w\") as tex:\n",
        "    tex.write(latex)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXypNFclia2M"
      },
      "source": [
        "# **EN DESARROLLO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6f4iaSsiaak"
      },
      "source": [
        "# Coeficientes con significancia (a, b, c)\n",
        "#coefs_con_significancia = pd.Series(colocar_letra_significancia(coef, \n",
        "#                                                                pvalues))\n",
        "#coefs_con_significancia = pd.Series(data=coefs_con_significancia.values, \n",
        "#                                    index = coef.index)\n",
        "\n",
        "\n",
        "def colocar_letra_significancia(coef, pvalues):\n",
        "\n",
        "  #######################################\n",
        "  # PENDIENTE:                          # \n",
        "  # * Documentar                        #\n",
        "  # * Paso previo de verificacion       #\n",
        "  #######################################\n",
        "\n",
        "  nivel_significancia_letra = nivel_significancia_letras(pvalues)\n",
        "\n",
        "  coefs_con_significancia = []\n",
        "\n",
        "  for i in range(len(coef)):\n",
        "\n",
        "    _coef_con_significancia_ = ('$ $' + str(coef[i]) + '^{'+ str(nivel_significancia_letra[i]) +'}$ $')\n",
        "\n",
        "    coefs_con_significancia.append(str(_coef_con_significancia_))\n",
        "\n",
        "  return coefs_con_significancia\n",
        "\n",
        "\n",
        "\n",
        "def nivel_significancia_letras(pvalues):\n",
        "\n",
        "  #######################################\n",
        "  # PENDIENTE:                          # \n",
        "  # * Documentar                        #\n",
        "  #######################################\n",
        "\n",
        "  ''' \n",
        "  pvalues:  (array_like)\n",
        "\n",
        "  '''\n",
        "\n",
        "  nivel_significancia_letras = pd.Series()\n",
        "\n",
        "  # Clasificacion del nivel de significancia\n",
        "  for i in range(len(pvalues)):\n",
        "\n",
        "    if pvalues[i] <= 0.01:\n",
        "      letra = 'a'                     # a: significancia 1%\n",
        "    elif pvalues[i] <= 0.05:                \n",
        "      letra = 'b'                     # b: significancia 5%\n",
        "    elif pvalues[i] <= 0.1:\n",
        "      letra = 'c'                     # c: significancia 10%\n",
        "    else:\n",
        "      letra = ''                           #    no significativo \n",
        "\n",
        "    letra = pd.Series(letra, index = [pvalues.index[i]])\n",
        "    nivel_significancia_letras = nivel_significancia_letras.append(letra)\n",
        "\n",
        "  nivel_significancia_letras = nivel_significancia_letras.fillna('')\n",
        "\n",
        "  return nivel_significancia_letras"
      ],
      "execution_count": 187,
      "outputs": []
    }
  ]
}